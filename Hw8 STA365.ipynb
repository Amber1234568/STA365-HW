{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e49ceee",
   "metadata": {},
   "source": [
    "# Homework 8: (a) Posterior Predictive Distributions<br> and (b) Missing Data Imputation\n",
    "\n",
    "### 1. Describe how the posterior predictive distribution is created for mixture models \n",
    "\n",
    "### 2. Describe how the posterior predictive distribution is created in general\n",
    "\n",
    "### 3. Have glance through [this](https://www.pymc.io/projects/examples/en/latest/case_studies/Missing_Data_Imputation.html) and then describe how, if you were doing a regression of $y$ on $X$ but $X$ had some missing values, you could perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
    "\n",
    "- **Hint: latent variables $v$ indicating the subpopulation are competely missing values that we simply treat as paramters to be inferred though posterior analysis... the same sort of thing can be done with missing values in data that need to be imputed... we should just be careful about the MCAR assumption...**\n",
    "\n",
    "### 4. Work on your course project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafe41f",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "First, Bayesian inference is performed on the parameters of the model using observed data to obtain the posterior distribution of the parameters. In mixture models, posterior distributions for each component's parameters are considered. The posterior predictive distribution is obtained by integrating over the posterior distributions of the parameters, often approximated using Monte Carlo methods. This involves sampling parameters from the posterior distribution and generating new data points with these parameters. The distribution of these new data points forms the posterior predictive distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb27103",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Obtaining the Posterior: Infer the parameters of your model given observed data to obtain their posterior distribution.\n",
    "\n",
    "Generating Predictive Data: Sample parameters from this posterior distribution and use them to generate potential unobserved data points.\n",
    "\n",
    "Aggregation of Predictions: Aggregate these predicted data points to form a comprehensive posterior predictive distribution, which reflects the probability distribution of unobserved data given the uncertainty in the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b78d9b",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "To handle missing data in regression analysis without discarding rows with missing values, Bayesian methods can be employed:\n",
    "\n",
    "Introduction of Latent Variables: Introduce latent variables for each missing value, representing the possible values of the missing data.\n",
    "\n",
    "Model Specification: Build a probabilistic model that encompasses both observed data and these latent variables.\n",
    "\n",
    "Inference and Imputation: Employ Bayesian inference techniques such as MCMC to estimate the joint posterior distribution of model parameters and the missing data. The posterior distribution of these latent variables provides inferences for the missing values.\n",
    "\n",
    "Iterative Updates: Iteratively, sample from the posterior distribution of latent variables to update estimates of missing values and refine parameter estimates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
